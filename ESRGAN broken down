import os
from PIL import Image
import random
import numpy as np
from tqdm import tqdm

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T
import torchvision.models as models
import torchvision.utils as vutils
import torch.optim as optim
import matplotlib.pyplot as plt

# 1. ─── Network Blocks ─────────────────────────────────────────────────────────

class ResidualDenseBlock(nn.Module):
    def __init__(self, in_channels=64, growth_channels=32):
        super().__init__()
        gc = growth_channels
        self.layers = nn.ModuleList([
            nn.Sequential(nn.Conv2d(in_channels + i*gc, gc, 3, 1, 1), nn.LeakyReLU(0.2, inplace=True))
            for i in range(5)
        ])
        self.lff = nn.Conv2d(in_channels + 5*gc, in_channels, 1, 1, 0)
        self.scale = 0.2

    def forward(self, x):
        features = [x]
        for layer in self.layers:
            out = layer(torch.cat(features, 1))
            features.append(out)
        out = self.lff(torch.cat(features, 1))
        return x + out * self.scale

class RRDB(nn.Module):
    def __init__(self, in_channels, growth_channels=32, num_blocks=3):
        super().__init__()
        self.blocks = nn.Sequential(*[
            ResidualDenseBlock(in_channels, growth_channels)
            for _ in range(num_blocks)
        ])
        self.scale = 0.2

    def forward(self, x):
        return x + self.blocks(x) * self.scale

# 2. ─── ESRGAN Generator & Discriminator ───────────────────────────────────────

class ESRGANGenerator(nn.Module):
    def __init__(self, in_nc=3, out_nc=3, nf=64, nb=23, gc=32):
        super().__init__()
        # First conv
        self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1)
        # RRDB trunk
        self.rrdb_trunk = nn.Sequential(*[RRDB(nf, gc) for _ in range(nb)])
        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1)
        # Upsampling
        up_layers = []
        for _ in range(2):  # 4× upscaling in two steps
            up_layers += [
                nn.Conv2d(nf, nf * 4, 3, 1, 1),
                nn.PixelShuffle(2),
                nn.LeakyReLU(0.2, inplace=True)
            ]
        self.upsampler = nn.Sequential(*up_layers)
        # Final convs
        self.conv_last = nn.Sequential(
            nn.Conv2d(nf, nf, 3, 1, 1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(nf, out_nc, 3, 1, 1)
        )

    def forward(self, x):
        fea = self.conv_first(x)
        trunk = self.trunk_conv(self.rrdb_trunk(fea))
        fea = fea + trunk
        out = self.upsampler(fea)
        return self.conv_last(out)

class Discriminator(nn.Module):
    def __init__(self, in_nc=3, nf=64):
        super().__init__()
        layers = []
        def d_block(in_ch, out_ch, stride):
            return [
                nn.Conv2d(in_ch, out_ch, 3, stride, 1),
                nn.LeakyReLU(0.2, inplace=True)
            ]
        channels = [in_nc, nf, nf, nf*2, nf*2, nf*4, nf*4, nf*8, nf*8]
        strides = [1, 2, 1, 2, 1, 2, 1, 2]
        for i in range(len(strides)):
            layers += d_block(channels[i], channels[i+1], strides[i])
        # classifier
        layers += [nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Linear(channels[-1], 100), nn.LeakyReLU(0.2, True), nn.Linear(100, 1)]
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        return self.model(x)

# 3. ─── Perceptual (VGG) Loss ──────────────────────────────────────────────────

class PerceptualLoss(nn.Module):
    def __init__(self, feature_layer=35):
        super().__init__()
        vgg = models.vgg19(pretrained=True).features
        self.slice = nn.Sequential(*[vgg[i] for i in range(feature_layer)]).eval()
        for p in self.slice.parameters():
            p.requires_grad = False
        self.criterion = nn.L1Loss()

    def forward(self, sr, hr):
        # normalize as VGG expects
        mean = torch.Tensor([0.485, 0.456, 0.406]).view(1,3,1,1).to(sr.device)
        std = torch.Tensor([0.229, 0.224, 0.225]).view(1,3,1,1).to(sr.device)
        sr_vgg = (sr - mean) / std
        hr_vgg = (hr - mean) / std
        return self.criterion(self.slice(sr_vgg), self.slice(hr_vgg))

# 4. ─── Dataset ────────────────────────────────────────────────────────────────

class SatelliteSRDataset(Dataset):
    def __init__(self, hr_dir, patch_size=128, scale=4):
        super().__init__()
        self.hr_files = [os.path.join(hr_dir, f) for f in os.listdir(hr_dir)]
        self.patch_size = patch_size
        self.scale = scale
        self.to_tensor = T.ToTensor()

    def __len__(self):
        return len(self.hr_files)

    def __getitem__(self, idx):
        hr = Image.open(self.hr_files[idx]).convert('RGB')
        # random crop on HR
        i, j, h, w = T.RandomCrop.get_params(hr, (self.patch_size, self.patch_size))
        hr_crop = hr.crop((j, i, j+w, i+h))
        # create LR by bicubic downsample
        lr = hr_crop.resize((self.patch_size//self.scale, self.patch_size//self.scale), Image.BICUBIC)
        # upsample back to HR size (optional: for architectures that take same size)
        lr_to_model = self.to_tensor(lr)
        hr_to_model = self.to_tensor(hr_crop)
        return lr_to_model, hr_to_model

# 5. ─── Training Loop ─────────────────────────────────────────────────────────

def train_esrgan(hr_dir, epochs=200, batch_size=4, lr=1e-4, device='cuda'):
    # Data
    dataset = SatelliteSRDataset(hr_dir)
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)

    # Models
    G = ESRGANGenerator().to(device)
    D = Discriminator().to(device)
    perc_loss = PerceptualLoss().to(device)
    l1_loss = nn.L1Loss()

    # Optimizers
    opt_G = optim.Adam(G.parameters(), lr=lr, betas=(0.9, 0.999))
    opt_D = optim.Adam(D.parameters(), lr=lr, betas=(0.9, 0.999))

    for epoch in range(1, epochs+1):
        loop = tqdm(loader, desc=f"Epoch {epoch}/{epochs}")
        for lr_imgs, hr_imgs in loop:
            lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)

            # ── Train Discriminator ──
            with torch.no_grad():
                fake = G(lr_imgs)
            pred_real = D(hr_imgs)
            pred_fake = D(fake)
            loss_D = torch.mean(pred_fake) - torch.mean(pred_real)
            opt_D.zero_grad()
            loss_D.backward()
            opt_D.step()

            # WGAN-GP or weight clipping could be added here if desired
            for p in D.parameters():
                p.data.clamp_(-0.01, 0.01)

            # ── Train Generator ──
            fake = G(lr_imgs)
            pred_fake = D(fake)
            loss_G_GAN = -torch.mean(pred_fake)
            loss_G_content = perc_loss(fake, hr_imgs)
            loss_G_l1 = l1_loss(fake, hr_imgs)
            loss_G = loss_G_content + 1e-3 * loss_G_GAN + 1e-2 * loss_G_l1

            opt_G.zero_grad()
            loss_G.backward()
            opt_G.step()

            loop.set_postfix({
                'lD': loss_D.item(),
                'lG': loss_G.item(),
                'lVGG': loss_G_content.item()
            })

        # save checkpoints
        torch.save(G.state_dict(), f"G_epoch{epoch}.pth")
        torch.save(D.state_dict(), f"D_epoch{epoch}.pth")

# 6. ─── Inference ─────────────────────────────────────────────────────────────

def super_resolve(image_path, model_path, device='cuda'):
    G = ESRGANGenerator().to(device)
    G.load_state_dict(torch.load(model_path, map_location=device))
    G.eval()

    img = Image.open(image_path).convert('RGB')
    lr = T.ToTensor()(img).unsqueeze(0).to(device)
    with torch.no_grad():
        sr = G(lr).clamp(0,1)
    # visualize
    sr_img = sr.squeeze().permute(1,2,0).cpu().numpy()
    plt.figure(figsize=(8,8))
    plt.imshow(sr_img)
    plt.axis('off')
    plt.title("Super-Resolved Image")
    plt.show()

# ──────────────────────────────────────────────────────────────────────────────
# Usage example (uncomment to run):
# train_esrgan("datasets/satellite/train_HR", epochs=100, batch_size=4)
# super_resolve("datasets/satellite/test_lr.jpg", "G_epoch100.pth")
